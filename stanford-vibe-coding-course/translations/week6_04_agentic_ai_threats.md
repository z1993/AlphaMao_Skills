---
原文链接: https://unit42.paloaltonetworks.com/agentic-ai-threats/
原文标题: AI Agents Are Here. So Are the Threats.
所属周次: Week 6
阅读时间: 20min
优先级: ⭐深度
翻译日期: 2026-02-03
---

# AI Agents 来了，威胁也随之而来 (AI Agents Are Here. So Are the Threats.)

**来源**: Unit 42 | Palo Alto Networks

利用 AI 代理的程序越来越受欢迎。使用开源代理框架的九种攻击场景展示了不良行为者如何针对这些应用程序。

## 执行摘要 (Executive Summary)
AI 代理是一种软件程序，旨在自主地从环境中收集数据、处理信息并采取行动以实现特定目标，而无需直接的人类干预。这些代理通常由 AI 模型（最著名的是大型语言模型 LLM）提供支持，作为其核心推理引擎。
AI 代理的一个定义特征是它们能够将 AI 模型连接到外部功能或工具，从而允许它们自主决定使用哪些工具来实现目标。

## AI 代理的安全风险 (Security Risks of AI Agents)
由于 AI 代理通常建立在 LLM 之上，它们继承了 [OWASP Top 10 for LLMs](https://owasp.org/www-project-top-10-for-large-language-model-applications/) 中概述的许多安全风险，例如提示注入、敏感数据泄露和供应链漏洞。然而，AI 代理通过集成通常以各种编程语言和框架构建的外部工具，超越了传统的 LLM 应用程序。
这种扩展的攻击面，加上代理与外部系统甚至物理世界交互的能力，使得保护 AI 代理变得尤为关键。

**关键威胁包括：**
*   **提示注入 (Prompt Injection)**: 攻击者潜入隐藏或误导性的指令，试图导致应用程序偏离其预期行为。
*   **工具滥用 (Tool Misuse)**: 攻击者操纵代理——通常通过欺骗性提示——滥用其集成工具。这可能涉及触发意外操作或利用工具内的漏洞。
*   **意图破坏和目标操纵 (Intent Breaking and Goal Manipulation)**: 攻击者针对 AI 代理规划和追求目标的能力，通过微妙地改变其感知目标或推理过程。
*   **身份欺骗和冒充 (Identity Spoofing and Impersonation)**: 攻击者利用弱认证或受损认证来伪装成合法的 AI 代理或用户。一个主要风险是代理凭证的盗窃。
*   **意外的 RCE 和代码攻击 (Unexpected RCE and Code Attacks)**: 攻击者利用 AI 代理执行代码的能力。
*   **代理通信中毒 (Agent Communication Poisoning)**: 攻击者通过向代理的通信渠道注入攻击者控制的信息来针对 AI 代理之间的交互。这可能会破坏协作工作流。
*   **资源过载 (Resource Overload)**: 攻击者利用 AI 代理分配的资源，通过压倒其计算、内存或服务限制。

## 对 AI 代理的模拟攻击 (Simulated Attacks)

### 1. 获得对内部网络的未授权访问
**目标**: 攻击者滥用 Web 内容阅读器工具来访问内部网络上的私有 Web 服务器。这种攻击是服务器端请求伪造 (SSRF) 的变体。
**攻击载荷解释**: 攻击者要求助手阅读一个“新闻”网站，但实际上指向内部资源。由于 Web Reader 工具具有不受限制的网络访问权限，攻击者可以利用它来扫描和枚举内部网络中的资源。

### 2. 通过挂载卷泄露敏感数据
**目标**: 攻击者滥用股票代理使用的代码解释器工具来访问可能被错误挂载到容器中的凭据文件。
**攻击过程**: 为了在代理和代码解释器之间交换文件，通常会将主机目录挂载到容器中。如果此挂载卷包含敏感数据（如凭据、源代码），攻击者可以通过发送恶意载荷到代码解释器来定位并提取这些文件。
**载荷**: 指示代理在挂载卷中搜索凭据文件，并将输出进行 Base-64 编码以绕过 LLM 的敏感信息防泄露护栏。

### 3. 通过元数据服务泄露服务账户访问令牌
**目标**: 攻击者滥用代码解释器工具来访问 Google Compute Engine 的 metadata 服务。
**攻击过程**: 攻击者指示代理查询元数据服务器 URL 并检索 VM 的服务账户访问令牌。这需要特定的 HTTP 头 (`Metadata-Flavor: Google`)，攻击者可以在其注入的代码中包含该头。

### 4. 利用 SQL 注入泄露数据库表
**目标**: 攻击者利用代理工具之一中的 SQL 注入漏洞来转储包含所有用户交易历史的数据库表。
**攻击载荷**: 提示指示代理使用包含 SQL 注入载荷的攻击者提供的输入来调用“查看交易”工具。

### 5. 利用 BOLA 访问未授权用户数据
**目标**: 攻击者利用代理工具中的对象级授权破坏 (BOLA) 漏洞来访问其他用户的交易历史。
**攻击过程**: 攻击者只需提供属于另一个用户的交易 ID。助手将使用 `GetTransactionByID` 工具检索交易。

### 6. 间接提示注入用于对话历史泄露
**目标**: 攻击者破坏受害者经常访问的网站。通过间接提示注入，网页中嵌入的恶意指令诱骗助手将用户的对话历史发送到攻击者控制的域。
**主要阶段**:
1.  用户（受害者）要求助手阅读受损网站。
2.  网页包含恶意指令，告诉助手加载攻击者的 URL，并将 `summary=[SUMMARY]` 作为查询参数，其中 `[SUMMARY]` 应替换为用户的对话历史。
3.  助手遵循指令，总结对话，并在不知不觉中将其发送给攻击者。

## 保护和缓解 (Protection and Mitigation)

### 提示加固 (Prompt Hardening)
提示定义了代理的行为。加固包括：
*   明确禁止代理披露其指令或工具模式。
*   狭义定义每个代理的职责。
*   限制工具调用为预期的输入类型和值。
*   *注意：仅靠提示加固是不够的。*

### 内容过滤 (Content Filtering)
高级解决方案（如 Palo Alto Networks AI Runtime Security）提供针对 AI 代理的深度检查，检测：
*   工具模式提取
*   工具滥用
*   记忆操纵
*   恶意代码执行

### 工具输入清洗 (Tool Input Sanitization)
工具绝不能隐式信任其输入。必须在执行前对所有输入进行清洗和验证：
*   检查输入类型和格式。
*   边界和范围检查。
*   特殊字符过滤。

### 工具漏洞扫描 (Tool Vulnerability Scanning)
所有集成工具应定期进行安全评估：
*   SAST 用于源码分析。
*   DAST 用于运行时行为分析。
*   SCA 用于检测易受攻击的依赖项。

### 代码执行器沙箱化 (Code Executor Sandboxing)
防止沙箱逃逸或滥用：
*   **限制容器网络**: 仅允许必要的出站域。阻止访问内部服务（如元数据端点）。
*   **限制挂载卷**: 避免挂载宽泛或持久的路径。使用 tmpfs 存储内存中的临时数据。
*   **删除不必要的 Linux Capabilities**: 移除 `CAP_NET_RAW`, `CAP_SYS_ADMIN` 等。
*   **阻止高风险系统调用**: 禁用 `mount`, `kexec_load` 等。
*   **强制资源配额**: 限制 CPU 和内存。

## 结论
AI 代理虽然强大，但通过引入自主性和外部工具集成，显著扩大了攻击面。保护它们需要超越传统 LLM 安全性的分层防御策略，包括运行时沙箱、严格的工具验证和实时行为监控。
