---
原文链接: https://www.dbreunig.com/2025/06/22/how-contexts-fail-and-how-to-fix-them.html
原文标题: How Long Contexts Fail
所属周次: Week 3
阅读时间: 15min
优先级: ⭐必读
翻译日期: 2026-02-03
---

# 长上下文是如何失效的 (How Long Contexts Fail)

管理好你的上下文是构建成功 Agent 的关键。仅仅因为有一百万个 Token 的上下文窗口，并不意味着你就应该把它填满。

**作者**: Drew Breunig
**日期**: 2025年6月22日

随着前沿模型上下文窗口的持续增长（许多已支持高达 100 万 Token），我通过观察发现，许多人兴奋地讨论长上下文窗口将如何解锁我们梦寐以求的 Agent。毕竟，有了足够大的窗口，你可以简单地将你可能需要的一切——工具、文档、指令等——都扔进 Prompt 中，然后让模型来处理剩下的事情。

长上下文削弱了人们对 RAG 的热情（既然可以把所有文档都放进 Prompt，何必去寻找最好的那个呢？），点燃了 MCP 的炒作（连接所有工具，模型就能做任何工作！），并助长了对 Agent 的热情。

但在现实中，更长的上下文并不意味着更好的回答。过载的上下文可能会导致你的 Agent 和应用程序以令人惊讶的方式失效。上下文可能会变得**中毒 (Poisoned)**、**令人分心 (Distracting)**、**令人困惑 (Confusing)** 或 **相互冲突 (Conflicting)**。这对于 Agent 来说尤其成问题，因为 Agent 依赖上下文来收集信息、综合发现并协调行动。

让我们浏览一下上下文可能失控的方式，然后回顾减轻或完全避免上下文失效的方法。

## 上下文失效 (Context Fails)

### 1. 上下文中毒 (Context Poisoning)
**上下文中毒是指幻觉或其他错误进入了上下文，并被反复引用的情况。**

DeepMind 团队在 [Gemini 2.5 技术报告](https://storage.googleapis.com/deepmind-media/gemini/gemini_v2_5_report.pdf)中指出了上下文中毒问题。在玩 Pokémon 时，Gemini Agent 偶尔会在游戏中产生幻觉，从而毒害其上下文：

> “这种问题的一种特别严重的形式是‘上下文中毒’——即上下文的许多部分（目标、摘要）被关于游戏状态的错误信息‘毒害’，这通常往往需要很长时间才能消除。结果，模型可能会固执地致力于实现不可能或不相关的目标。”

如果其上下文中的“目标”部分被毒害，Agent 就会制定荒谬的策略并重复行为，以追求一个无法实现的目标。

### 2. 上下文分心 (Context Distraction)
**上下文分心是指上下文变得太长，以至于模型过度关注上下文，而忽略了它在训练中学到的东西。**

随着 Agent 工作流中上下文的增长——随着模型收集更多信息并建立历史记录——这种积累的上下文可能会变得令人分心而不是有所帮助。玩 Pokémon 的 Gemini Agent 清楚地展示了这个问题：

> “虽然 Gemini 2.5 Pro 支持 1M+ 的 Token 上下文，但有效地将其用于 Agent 是一个新的研究前沿。在这个 Agent 设置中，我们观察到，随着上下文显著增长并超过 100k Token，Agent 表现出一种倾向，即更喜欢重复其庞大历史中的动作，而不是综合新的计划。这种现象虽然是轶事，但强调了用于检索的长上下文与用于多步生成推理的长上下文之间的重要区别。”

Agent 不再使用其训练来开发新策略，而是变得固执地重复其广泛上下文历史中的过去动作。

对于较小的模型，分心的上限要低得多。一项 [Databricks 研究](https://www.databricks.com/blog/long-context-rag-performance-llms)发现，Llama 3.1 405b 的模型正确性在 32k左右开始下降，而较小的模型则更早。

如果模型在上下文窗口被填满之前很久就开始表现不佳，通过超大上下文窗口还有什么意义呢？简而言之：**摘要 (Summarization)** 和 **事实检索 (Fact Retrieval)**。如果你不通过这两者，请警惕你所选模型的分心上限。

### 3. 上下文困惑 (Context Confusion)
**上下文困惑是指上下文中的多余内容被模型用来生成低质量的响应。**

有一段时间，似乎每个人都会发布一个 [MCP](https://modelcontextprotocol.io/)。一个强大的模型，连接到你所有的服务和东西，做你所有琐碎任务的梦想似乎触手可及。只需将所有工具描述扔进 Prompt 并点击运行。[Claude 的系统提示词](https://docs.anthropic.com/en/release-notes/system-prompts)向我们展示了这种方式，因为它主要是工具定义或使用工具的说明。

但是，即使整合和竞争没有减缓 MCP 的发展，上下文困惑也会。事实证明，**工具太多也是一种负担**。

[伯克利函数调用排行榜 (Berkeley Function-Calling Leaderboard)](https://gorilla.cs.berkeley.edu/leaderboard.html) 是一个评估模型有效使用工具能力的基准。现在是第 3 版，排行榜显示，当提供多个工具时，每个模型的表现都会变差。此外，伯克利团队设计了一些场景，“其中提供的函数都不相关……我们期望模型的输出是没有函数调用。”然而，所有模型偶尔都会调用不相关的工具。

浏览函数调用排行榜，你可以看到随着模型变小，问题会变得更糟。

[最近的一篇论文](https://arxiv.org/pdf/2411.15399)中可以看到上下文困惑的一个惊人例子，该论文评估了小模型在 [GeoEngine 基准](https://arxiv.org/abs/2404.15500)上的表现，该试验包含 46 种不同的工具。当团队给量化（压缩）的 Llama 3.1 8b 一个包含所有 46 个工具的查询时，它失败了，即使上下文完全在 16k 上下文窗口内。但当他们只给模型 19 个工具时，它成功了。

问题是：如果你在上下文中放入了一些东西，模型就必须注意它。这可能是不相关的信息或不必要的工具定义，但模型会将其考虑在内。大型模型，尤其是推理模型，在忽略或丢弃多余上下文方面变得越来越好，但我们不断看到无价值的信息绊倒 Agent。更长的上下文让我们塞入更多信息，但这种能力也有其缺点。

### 4. 上下文冲突 (Context Clash)
**上下文冲突是指你在上下文中积累的新信息和工具与上下文中的其他信息发生冲突。**

这是上下文困惑的一个更有问题的版本：这里的坏上下文不是不相关的，而是直接与 Prompt 中的其他信息冲突。

Microsoft 和 Salesforce 团队在[最近的一篇论文](https://arxiv.org/pdf/2505.06120)中精彩地记录了这一点。该团队从多个基准中提取 Prompt，并将其信息“分片”到多个 Prompt 中。可以这样想：有时，你可能会坐下来在 ChatGPT 或 Claude 中输入段落，然后在点击回车之前考虑每个必要的细节。其他时候，你可能会从一个简单的 Prompt 开始，然后在聊天机器人的回答不令人满意时添加更多细节。Microsoft/Salesforce 团队修改了基准 Prompt，使它们看起来像这些多步交换：

分片的 Prompt 产生了显著更差的结果，平均下降了 39%。团队测试了一系列模型——OpenAI 自豪的 o3 的得分从 98.1 降至 64.1。

发生了什么？如果信息是分阶段收集的而不是一次性收集的，为什么模型的表现会更差？

答案是 **上下文困惑 (Context Confusion)**：组装的上下文包含了聊天的全部内容，其中包含模型在拥有所有信息之前回答挑战的早期尝试。这些错误的答案保留在上下文中，并在模型生成最终答案时影响模型。团队写道：

> “我们发现 LLM 经常在早期回合中做出假设，并没有成熟地尝试生成最终解决方案，他们过度依赖这些解决方案。简单来说，我们发现当 LLM 在对话中转错弯时，它们会迷路并且无法恢复。”

这对 Agent 构建者来说不是好兆头。Agent 从文档、工具调用以及负责子问题的其他模型中组装上下文。所有这些从不同来源提取的上下文都有可能与自身不一致。此外，当你连接到你不创建的 MCP 工具时，它们的描述和说明与 Prompt 的其余部分发生冲突的可能性更大。

## 结论
百万 Token 上下文窗口的到来感觉具有变革性。将 Agent 可能需要的一切都扔进 Prompt 的能力激发了对超级智能助手的愿景，这些助手可以访问任何文档，连接到每个工具，并保持完美的记忆。

但正如我们所见，更大的上下文创造了新的失效模式。
- **上下文中毒**嵌入了随时间推移而复合的错误。
- **上下文分心**导致 Agent 严重依赖其上下文并重复过去的动作，而不是向前推进。
- **上下文困惑**导致不相关的工具或文档使用。
- **上下文冲突**造成了破坏推理的内部矛盾。

这些故障对 Agent 的打击最大，因为 Agent 正是在上下文膨胀的场景中运行的：从多个来源收集信息，进行顺序工具调用，通过多轮推理，并积累广泛的历史记录。

幸运的是，有解决方案！在下一篇文章中，我们将介绍减轻或避免这些问题的技术，从动态加载工具的方法到启动上下文隔离区。

请阅读后续文章：“[如何修复你的上下文](https://www.dbreunig.com/2025/06/26/how-to-fix-your-context.html)”

---

## 关键术语

| 英文 | 中文 | 说明 |
|------|------|------|
| Context Poisoning | 上下文中毒 | 错误信息进入上下文并被模型反复引用 |
| Context Distraction | 上下文分心 | 模型过度关注历史上下文而忽略训练知识 |
| Context Confusion | 上下文困惑 | 多余或不相关的信息干扰模型生成质量 |
| Context Clash | 上下文冲突 | 新信息与上下文中的旧信息发生矛盾 |
| Hallucination | 幻觉 | 模型生成看似合理但实际上错误的信息 |
| Token | 令牌 | LLM 处理文本的基本单位 |
