---
原文链接: https://research.trychroma.com/context-rot
原文标题: Context Rot: How Increasing Input Tokens Impacts LLM Performance
所属周次: Week 6
阅读时间: 15min
优先级: ⭐深度
翻译日期: 2026-02-03
---

# 上下文腐烂：增加输入 Token 如何影响 LLM 性能 (Context Rot)

**来源**: Chroma Research
**核心**: 随着上下文窗口 (Context Window) 的增长，主要 LLM 在处理长输入时的性能会下降，这种现象被称为“上下文腐烂 (Context Rot)”。

## 介绍
现代 LLM 拥有数百万 Token 的输入上下文长度是很常见的（如 Gemini 1.5 Pro, GPT-4o, Llama 4）。长上下文的用例非常诱人：这意味着 LLM 可以在每次调用中处理更多信息。
然而，现有的长上下文评估（如“大海捞针” NIAH）通常范围狭窄，不能代表实际使用情况。NIAH 只是一个简单的词汇检索任务。
我们的实验通过保持任务复杂性不变，仅改变输入长度，来直接测量输入长度本身的影响。

## 1. 针-问题相似度 (Needle-Question Similarity)
在现实世界的应用中，模型通常被期望处理模糊的任务。
我们改变了“针”（答案所在的段落）和“问题”之间的相似度。我们发现，**随着针-问题相似度的降低，模型性能随着输入长度的增加而下降得更显著。**
这反映了更现实的场景，即精确的问答匹配很少见，语义模糊加剧了长输入处理的挑战。

## 2. 干扰项的影响 (Impact of Distractors)
干扰项（Distractors）是指上下文中与问题无关但可能混淆模型的信息。
我们的实验表明，**随着输入长度的增加，干扰项的影响及其非均匀性在所有模型中都会放大**，包括最新的 SOTA 模型。

## 3. 针-干草堆相似度 (Needle-Haystack Similarity)
通常假设无关上下文（干草堆）的内容并不重要，只要它不直接干扰任务即可。
我们的发现揭示了**针-干草堆相似度对模型性能有非均匀的影响**。直觉上，如果针与干草堆的内容融合在一起，模型提取针的难度可能会更大。

## 4. 干草堆结构 (Haystack Structure)
我们创建了两个变体：
1.  **原始 (Original)**: 保留每个摘录内的自然思路流。
2.  **打乱 (Shuffled)**: 句子被随机重新排序，以保持相同的整体主题但没有逻辑连续性。

**结果**: 在所有 18 个模型中，我们观察到一个一致的模式，即**模型在打乱的干草堆上的表现优于逻辑结构的干草堆**。
这可能意味着输入的结构模式会影响注意力机制的应用方式。理解这些结构影响可能有助于解释长上下文失败模式。

## 5. LongMemEval 实验
给定用户和助手之间的聊天历史，模型的任务是回答有关该聊天历史部分的问题。
这是一个更贴近实际 RAG 或 Agent 记忆的场景。
**结果**: 在所有模型中，我们看到**聚焦提示 (Focused Prompts)** 的性能明显高于**完整提示 (Full Prompts)**。
*   **Claude 系列**: 表现出最明显的差距。Claude Opus 3.5 和 Sonnet 3.5 在模糊性下显得特别保守（倾向于拒绝回答），导致相对于旧版 Claude 模型，在全提示上的性能较低。
*   **思维模式 (Thinking Mode)**: 对于支持思维模式的模型，启用后我们看到聚焦提示和全提示的性能都有显著提升。然而，即使有了推理能力，两个输入长度之间的性能差距仍然存在。

## 结论与局限性
即使是最先进的模型，随着上下文的增加，也会遭受性能退化——即上下文腐烂。
*   这挑战了“不仅仅将所有内容放入上下文窗口”的简单想法。
*   对于构建 Agent 和 RAG 系统，这意味着**上下文工程 (Context Engineering)**、**修剪 (Pruning)** 和**压缩 (Compaction)** 仍然是必要的，不能完全依赖模型的长上下文能力。

## 附录：测试的模型
涵盖了 Claude (Haiku, Sonnet, Opus), OpenAI (GPT-4o, o1-preview), Gemini, Llama 等主流模型系列。
